# AI Transparency Commons

> **v0.1 DRAFT** — Seeking feedback before public release

> The following was dictated into my phone as a stream-of-consciousness essay and cleaned up for spelling and grammar. `Ah-Eh-Rm`

---

One of the difficult things I think we all face—and that this project in particular faces—is the ambiguity surrounding what is and isn't generative creativity.

Music is full of comparisons between using loops, drum machines, and virtual performers. I don't think many producers would think to label their own productions using Logic Drummer as generative assistance. In fact, there are norms that we have mostly gotten used to that hug the borders between human and machine.

No one would want to label their writing as AI-assisted because they used spell check. But how about grammar check? Or what about predictive text?

Because a lot of conceptions around this topic are going to change, it really requires us to acknowledge that some of this has to do with social norms and conventions. To that end, I think it would be useful to create a running list of examples to see how people might interpret various scenarios.

---

In the interest of being transparent but not judgmental, I think we have to acknowledge that anyone using the system is making a good-faith attempt to be transparent.

But all sorts of people might choose to code their creative work differently. A traditionalist who prides themselves on doing everything by hand is going to interpret human origin one way, and someone who chooses to allow a large language model to generate some random images in order to inspire a songwriting session might claim the same.

The common factor between both of them is the desire to disclose, and I think it is the common human desire to take credit for our own ideas while acknowledging the force multiplier which is the lever we apply against them.

---

This system is not about keeping track of whether the agent on the other end of the line when you call to pay your phone bill is a real person or not. It's not about determining if one model is biased or if the safety guardrails are intact on another. These are valid concerns but separate issues.

This initiative is about the very human desire to give ourselves credit for our own ingenuity while acknowledging the use of tools.

---

### About this disclosure

**Code:** `Ah-Eh-Rm` — Authorship: human, Execution: human, Refinement: machine

**What that means:** I wrote this. An AI cleaned it up for spelling and grammar. Changes included:
- "logic drummer" → "Logic Drummer"
- "AI assisted" → "AI-assisted"
- "guard rails" → "guardrails"
- Minor punctuation

The ideas and words are mine. The proofreading wasn't.

---

## Purpose

A simple, voluntary system for creators to disclose how they use AI—not whether they do.

---

## What This Project Is

Inspired by Creative Commons. Few elements, flexible combinations, human-readable codes that creators can apply to their own work.

---

## Mission

To create a shared vocabulary for transparency around AI use in creative work—one that is understandable, future-proof, non-judgmental, and inclusive.

---

## First: We Need a Name

Creative Commons works because it's a good idea with a name people can understand. The term "AI" is loaded and may not age well. Before we finalize anything, we need to get the naming right.

**[Join the naming discussion →](discussions/NAMING.md)**

---

## Get Involved

- **[Read the specification](SPECIFICATION.md)** — The technical framework
- **[See how this project was made](archive/bak-genisis.md)** — Full transparency on the process
- **[Previous README](archive/README-v1.md)** — Earlier version of this document

---

## License

This work is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).

You are free to share and adapt this framework for any purpose, provided you give appropriate credit.

---

**Founded by Nathan Rosenberg / [BeatKitchenSchool](https://github.com/BeatKitchenSchool)**
